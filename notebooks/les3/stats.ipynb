{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Assumptions\n",
    "\n",
    "Usually, you will start with empirical data.\n",
    "\n",
    "You might have educated guesses about the distributions, but you are often not sure.\n",
    "\n",
    "Let's see how to test this.\n",
    "\n",
    "## Preprocess\n",
    "First, we preprocess the penguins data so that we only have the floating point data for continuous distributions\n",
    "\n",
    "Jupyter notebook will search in our kernel for packages, but it won't know where to find our own src package. But we can add our current working directory with `\".\"` to `sys.path`, which lists all the locations where python will try to find packages.\n",
    "\n",
    "If you are curious, just print `sys.path` to have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\")\n",
    "from src.settings import modelsettings\n",
    "from src import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (\"../..\" / modelsettings.processed_dir / \"processed.parq\").resolve()\n",
    "p = preprocess.prepare_floats(filename, modelsettings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have melted and normalized data.\n",
    "\n",
    "\n",
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data = p.to_pandas(), x = 'variable', y='norm', hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are this normal distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(p.to_pandas(), x=\"norm\", hue=\"variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe, maybe not..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(p.to_pandas(), col=\"variable\", hue=\"species\")\n",
    "g.map_dataframe(sns.kdeplot, x=\"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the type of distribution, we can still indicate how easy it will be to separate, for example, species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing distributions\n",
    "\n",
    "Let's select, from the species \"Adelie\", the length of the flipper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = p.select(pl.col(\"variable\").unique())[\"variable\"].to_list()\n",
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = p.filter((pl.col(\"variable\") == \"fliplen\") & (pl.col(\"species\") == \"Adelie\"))[\"norm\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `Fitter` library to fit a distribution.\n",
    "Let's test these four distrubutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fitter import Fitter, get_common_distributions\n",
    "d = [\"uniform\", \"lognorm\", \"norm\", \"gamma\"] \n",
    "d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit, and make a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Fitter(x, distributions=d)\n",
    "f.fit()\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the parameters of the best fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.get_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or from all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fitted_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitter uses the pylab backend hardcoded. But we can hack the fitter object, by studying the [source code](https://fitter.readthedocs.io/en/latest/_modules/fitter/fitter.html#Fitter).\n",
    "\n",
    "- There is a `self.get_best()` method that provides the parameters of the best fit.\n",
    "- `self._data` provides us with the raw data for the historgram\n",
    "- We can use `self.df_errors` to get a dataframe of the best fits. If we sort it, we can obtain the top 5 distributions.\n",
    "- `plt.plot(f.x, f.fitted_pdf[name])` gives us the fitted pdf. `name` should be the name of the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import visualization\n",
    "fig, ax = plt.subplots()\n",
    "visualization.custom_summary(f, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives almost the same result, but we have more control over the details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the distributions are sort of close. But most probable, a normal distribution in this case.\n",
    "\n",
    "Another, more informal way to check, is with a qq-plot (quantile-quantile plot) to visually test how the samples compare to the theoretical output for a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.probplot(x, dist=\"norm\", plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there are still some outliers at the end. A perfect fit would line up along the red line.\n",
    "\n",
    "Wrapping this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualization.test_distribution(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is confirmative for a normal distribution.\n",
    "Now, let's try the same for one of the bloodlevel values, $\\Delta 13$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = p.filter((pl.col(\"variable\") == 'Î”13') & (pl.col(\"species\") == \"Adelie\"))[\"norm\"].to_list()\n",
    "f = visualization.test_distribution(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the normal distribution is not even in the top 5!\n",
    "\n",
    "You should be carefull, however, to just pick the number 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df_errors.sort_values(by=\"sumsquare_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the top 3 is pretty close. A gamma distribution has 4 parameters, so that is what makes it really flexible. \n",
    "\n",
    "A lognormal could be a good pick here, but I would prefer to dive deeper into the underlying groups. It could be that the distribution returns to two normal distributions, for example if you split the data into male/female.\n",
    "\n",
    "Also, I would want to talk to an expert about what is going on, to find out if this makes sense.\n",
    "\n",
    "However, the most important conclusion: this is NOT a normal distribution, and you can't use anything that assumes a normal distribution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
