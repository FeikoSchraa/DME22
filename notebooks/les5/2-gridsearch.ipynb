{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Grid Search with Cross-Validation\n",
    "\n",
    "## Information Leaks\n",
    "\n",
    "It's important to create an additional validation set next to the training and test set. When you are applying machine learning methods in practice choices made on the test set accuracy \"leak\" information from the test set into the model. \n",
    "\n",
    "Imagine your announcement to your datascience team that you made an absolutely fantastic model with 98% accuracy, only to find out later on that you overfitted and your model performs really poor on new data. That's something you want to avoid, I assume.\n",
    "\n",
    "As you never want to leak any information to have a good generalization\n",
    "perspective it is important to always **keep an isolated validation set**, so\n",
    "the final evaluation of the model is completely independent.\n",
    "\n",
    "## Fitting a model\n",
    "\n",
    "The basic drill is:\n",
    "\n",
    "1. make a train-test split\n",
    "2. Explore the data, preprocess where needed\n",
    "2. select and import a model, set some hyperparameters\n",
    "3. fit the model\n",
    "4. evaluate the model\n",
    "\n",
    "Now, let's see that in code. The most basic syntax is:\n",
    "\n",
    "``` \n",
    "from sklearn import Model # import the model\n",
    "model = Model(parameters) # set parameters\n",
    "model.fit(train_X, train_y) # fit on the data\n",
    "```\n",
    "\n",
    "\n",
    "And we can predict:\n",
    "\n",
    "`yhat = model.predict(test_X)`\n",
    "\n",
    "and calculate a score with the metric we pick.\n",
    "\n",
    "## Manual Grid Search Workflow\n",
    "\n",
    "In the code cell below you can see the overall workflow of running a grid\n",
    "search, and evaluating the final parameter. \n",
    "\n",
    "As a model, we will use a Suport Vector Machine. For now, don't bother what that\n",
    "is exactly. All you need to know for now, is that it is a type of model we will\n",
    "import, set parameters for and fit on the traindata, and then test the\n",
    "prediction on the testset.\n",
    "\n",
    "We will use parameters $C$ and $\\gamma$. \n",
    "You can see all parameters this model take by running `help()` or `?` or `dir()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "help(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data, drop the categorical features for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset(\"penguins\")\n",
    "data = data.drop([\"island\", \"sex\"], axis=1).dropna()\n",
    "y = data[\"species\"]\n",
    "X = data.drop(\"species\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train-test-validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "            X_test, y_test, test_size=0.5, random_state=42\n",
    "        )\n",
    "print(f\"trainsize: {X_train.shape}, testsize: {X_test.shape}, validsize: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction, and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = svm.predict(X_valid)\n",
    "(yhat == y_valid).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's nice. We have 3 classes; if they are balanced (how could you check that?), we would expect a random model to do about 33% accuracy. But we are already at 67%. But maybe we can do better by changing the hyperparameters? Let's test a range of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "gamma = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "parametergrid = [*itertools.product(gamma, C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grid search over parameter grid, to find best parameters\n",
    "best_score = 0 \n",
    "# note that there are even more parameters for a SVC that we could play with. \n",
    "# See sklearn documentation for more details.\n",
    "for param in parametergrid:\n",
    "\n",
    "    # Initialize SVC model for given combination of parameters\n",
    "    svm = SVC(gamma=param[0], C=param[1])\n",
    "\n",
    "    # Train on train set\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate validation set \n",
    "    score = svm.score(X_valid, y_valid)\n",
    "\n",
    "    # Store the best score \n",
    "    if score > best_score: \n",
    "        best_score = score \n",
    "        best_parameters = {'C': param[1], 'gamma': param[0]}\n",
    "\n",
    "\n",
    "# Initiatize model with best parameters\n",
    "# Note that '**' (dereference operator) is used to convert the dict into parameters\n",
    "svm = SVC(**best_parameters)\n",
    "\n",
    "# Train on train set\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Score on test set\n",
    "test_score = svm.score(X_test, y_test)\n",
    "\n",
    "# Print scores\n",
    "print(\"Test set score with best parameters:  {:.2f}\".format(test_score))\n",
    "print(\"Best score on validation set:         {:.2f}\".format(best_score))\n",
    "print(\"Best parameters:                     \", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the testset is better than the validation set. This could point to some overfitting, but it might also be caused by our small sets: with just 35 items in the test and validation set, its very easy to have a few percentage points difference just by an (un)lucky split..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "While this works, scikit-learn has automated this for you. This is not just less work, it also guards you against errors. So. let's have a look at a more automated and robust version with **GridSearchCV**.\n",
    "\n",
    "Although splitting the data into a training, validation and test set is workable, this approach can be sensitive to how exactly the data is split. Picking settings, based on just a very small set of 10% of the data is very sensitive to errors, especially if the dataset is small. So, for better generalization performance, cross-validation is a more sophisticated method to evaluate the performance of each parameter.\n",
    "\n",
    "We will split again, and don't make a separate validation set: gridsearch will do that for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides the **`GridSearchCV`** class, which implements a gridsearch with cross-validation in the form of an estimator. Before instantiating the `GridSearchCV` class, we need to specify the parameters of interest using a dictionary. In this dictionary the keys refer to the parameters we want to adjust and the values are the parameter settings we are interested in. \n",
    "\n",
    "let's use list comprehensions to quickly make a range of values with big steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[10**x for x in range(-3,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap these lists of values into a parameter dictionary, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter grid\n",
    "param_grid = {'C': [10**x for x in range(-4,3)],\n",
    "              'gamma': [10**x for x in range(-4,1)]}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty wide scan; we are scanning 7 orders of magnitude! That is a huge area, but we are just trying to pinpoint the hotspots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can run a fully automatied Cross validation Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "\n",
    "# Display GridSearchCV object\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` will perform all necessary steps to fit the model. Moreover it will run cross validation for each combination of parameters that we specified.\n",
    "\n",
    "This means it will make multiple (we specified 3) splits of the data for training and testing the performance. If we increase `cv` to for example `cv=5`, gridsearch will split the data five different times, to make sure the impact of the train-test split is as low as possible.\n",
    "\n",
    "It will fit a new model on the whole training dataset for every time a split is made, and make a final model with the best parameters that were found during the cross validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a Grid Search and automatically fit using best parameters\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print best parameters and corresponding score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:  {}\".format(best_parameters))\n",
    "print(\"Best score:       {:.2f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, let's visualize what we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization import visualize\n",
    "visualize.gridsearch_heatmap(grid_search, param_grid, figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have a hotspot. But our scan is very rough: every value we test is 10 times as big. We will probably want to do this a bit more finegrained.\n",
    "\n",
    "however, this is very usefull for a quick scan. So let's wrap this in a function, and repeat this while zooming in on the heatmap. The process is this:\n",
    "\n",
    "1. Make sure that your first gridsearch is large enough to have 'low performance' in the borders.\n",
    "2. Zoom in on the hotspot, tuning up the gradient of the parameters. Make sure you dont overdo: 25 values for C and 25 values for gamma results in 25x25 combinations. This can take quite some time if you overdo this (eg a grid with 100 values of $C$ and 100 values of $\\gamma$ results in 10.000 times fitting the SVC.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import train_model\n",
    "\n",
    "# Set parameter grid\n",
    "# zoom in on what looks like a usefull are for C and gamma\n",
    "param_grid = {\n",
    "    'C': np.linspace(10, 500, 20),\n",
    "    'gamma': np.linspace(1e-7, 1e-3, 20),\n",
    "    }\n",
    "\n",
    "\n",
    "# often it is usefull to fiddle with the vmin to increase the contrast of colors\n",
    "grid_search = train_model.search_and_fit(model=SVC(),\n",
    "                                         X=X_train, \n",
    "                                         y=y_train, \n",
    "                                         param_grid=param_grid, \n",
    "                                         vmin=0.7,\n",
    "                                         figsize=(15,15),\n",
    "                                         cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the optimal gamma is low, the optimal C is pretty high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter grid\n",
    "# zoom in on what looks like a usefull are for C and gamma\n",
    "param_grid = {\n",
    "    'C': np.linspace(50, 200, 20),\n",
    "    'gamma': np.linspace(1e-7, 1e-4, 20),\n",
    "    }\n",
    "\n",
    "\n",
    "# often it is usefull to fiddle with the vmin to increase the contrast of colors\n",
    "grid_search = train_model.search_and_fit(model=SVC(),\n",
    "                                         X=X_train, \n",
    "                                         y=y_train, \n",
    "                                         param_grid=param_grid, \n",
    "                                         vmin=0.8,\n",
    "                                         figsize=(15,15),\n",
    "                                         cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print best parameters and corresponding score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:  {}\".format(best_parameters))\n",
    "print(\"Best score:       {:.2f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A question that is not straightforward to answer, is: are the 'best parameters' returned by the grid search, actually the best parameters?\n",
    "\n",
    "Look at the heatmap; you can often find little islands of good practice.\n",
    "\n",
    "The downside of an island is, that you might \"drop off\" and fall into a deep\n",
    "abyss of low performance if the data changes just a little bit.\n",
    "\n",
    "That's why I would prefere a big area of high performance and picking the middle\n",
    "of that over letting the automated process pick a higher perform that's in the\n",
    "middle of a very small spot.\n",
    "\n",
    "At a minimum, you should check it visually.\n",
    "\n",
    "# Adding pipelines\n",
    "Another usefull feature is to create a pipeline of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = sns.load_dataset(\"penguins\")\n",
    "data = data.drop([\"island\", \"sex\"], axis=1).dropna()\n",
    "y = data[\"species\"]\n",
    "X = data.drop(\"species\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Build pipeline\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()), # we add a scaler\n",
    "        (\"svm\", SVC()) # and a model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, if you have multiple steps in your process, it's a good idea to\n",
    "fixate the steps with a function. This protects you from making mistakes in the\n",
    "order of the process. In addition to that, this fixes the problem with the order\n",
    "of scaling and splitting: this wil fit the scaler on the training, and apply\n",
    "that fit to the testset.\n",
    "\n",
    "In the example below, you see combined the scaler and the SVC. You can add more functions to\n",
    "that, and usually you will. In a real life dataset, your preprocessing might\n",
    "contain more then ten steps and contain cleaning, modification (like scaling), feature\n",
    "extraction, etc.\n",
    "\n",
    "A Pipeline is a nice way to fixate multiple steps in a proces.\n",
    "It takes a list of name-estimator pairs. \n",
    "\n",
    "```\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"name_of_first_estimator\", FirstEstimator()), \n",
    "        (\"name_of_second_estimator\", SecondEstimator())\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "All but the last one must\n",
    "be transformers (meaning, they must implement a `fit_transform()` method),\n",
    "something that all sklearn models do. But you can easily create a custom\n",
    "transformer if you implement this method.\n",
    "\n",
    "Calling `fit()` on the pipe calls the `fit_transform()` methods sequentially,\n",
    "and `fit()` on the final method.\n",
    "\n",
    "If you want to feed a range of parameters, you can give `GridSearchCV` a\n",
    "dictionary with `{str: List}` pairs. To indicate which key should be used for\n",
    "which estimator, you should use a double underscore.\n",
    "\n",
    "So, if the name you gave to and estimator is \"scaler\", the `GridSearchCV`\n",
    "function will look for \"scaler__parameter\". Look at the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note the double underscore in the parameter names. This refers to the name-estimator pairs in the pipeline.\n",
    "param_grid = {'svm__C': [10**x for x in range(-4,3)],\n",
    "              'svm__gamma': [10**x for x in range(-4,1)]}\n",
    "\n",
    "gridsearch = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Print results (CV accuracy, test set score, best parameters)\n",
    "print(gridsearch.best_score_)\n",
    "print(gridsearch.score(X_test, y_test))\n",
    "print(gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how adding the scaler means we need to start the hyperparameter tuning again!\n",
    "Changing the scales can impact the scales of the hyperparameters a lot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, this is exectly the same as what we did before. It just wraps more into a solid architecture, making sure that all steps in the datapreparation are executed in the right sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.gridsearch_heatmap(gridsearch, param_grid, vmin=0.9, figsize=(10,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dme22-EYaUUFkp-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7860b014c314f311c8b672f44810aa9dc3f93fa03e0304fc46ef46d9eb93290"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
