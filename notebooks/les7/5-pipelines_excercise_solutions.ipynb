{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Author: Frank E. Harrell Jr., Thomas Cason  Source: [Vanderbilt Biostatistics](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.html)   \n",
    "<br/><br/>\n",
    "\n",
    ">The original Titanic dataset, describing the survival status of individual passengers on the Titanic. The titanic data does not contain information from the crew, but it does contain actual ages of half of the passengers. The principal source for data about Titanic passengers is the Encyclopedia Titanica. The datasets used here were begun by a variety of researchers. One of the original sources is Eaton & Haas (1994) Titanic: Triumph and Tragedy, Patrick Stephens Ltd, which includes a passenger list created by many researchers and edited by Michael A. Findlay.  \n",
    "<br/><br/>\n",
    ">Thomas Cason of UVa has greatly updated and improved the titanic data frame using the Encyclopedia Titanica and created the dataset here. Some duplicate passengers have been dropped, many errors corrected, many missing ages filled in, and new variables created.   For more information about how this dataset was constructed: http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3info.txt   \n",
    "\n",
    "### Attribute information\n",
    "The variables on our extracted dataset are pclass, survived, name, age, embarked, home.dest, room, ticket, boat, and sex. \n",
    "\n",
    "\n",
    "- survival: Survival (0 = No, 1 = Yes)\n",
    "- pclass:\tTicket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- sex:\tSex\t\n",
    "- Age:\tAge in years\t\n",
    "- sibsp:\t# of siblings / spouses aboard the Titanic\t\n",
    "- parch:\t# of parents / children aboard the Titanic\t\n",
    "- ticket:\tTicket number\t\n",
    "- fare:\tPassenger fare\t\n",
    "- cabin:\tCabin number\t\n",
    "- embarked:\tPort of Embarkation(C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=y,y='fare',data=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a correlation between the fare payed, and survival chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=y,y='age',data=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age does not seem to impact by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "p = pd.concat([X, y], axis=1)\n",
    "g = sns.FacetGrid(p, col=\"sex\",  row=\"pclass\")\n",
    "g.map(sns.boxplot, \"survived\", \"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in a facet grid, there seems to be a correlation for some groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='pclass',y='age',data=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's hard to tell if that is a causal relationship, or if it's just because of the correlation with other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some nan's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop([\"cabin\", \"ticket\", \"boat\", \"body\", \"home.dest\", \"name\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop some variables that are probably not informative. It could still be the case that they correlate with something else. E.g., imagine home destination to be correlated with the location on the deck, which in term could be correlated with survival chances.\n",
    "\n",
    "A train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X_train.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have soms nans. Let's use a `SimpleImputer` for that. For the numeric data we use the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the categorical, let's use most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[ \n",
    "    \t('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "\t('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine this into a preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = preprocessor.fit_transform(X_train)\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work as expected!\n",
    "\n",
    "Let's test a basic logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, HalvingGridSearchCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "param_dist = {'svc__C': stats.expon(scale=10), 'svc__gamma': stats.expon(scale=1)}\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('svc', SVC())])\n",
    "\n",
    "sh = HalvingRandomSearchCV(clf, param_dist, \n",
    "\t\t\tcv=5,\n",
    "      factor=2,\n",
    "      random_state=0)\n",
    "sh.fit(X_train, y_train)\n",
    "sh.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model score: %.3f\" % sh.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a RFC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfc', RandomForestClassifier())])\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\"rfc__max_depth\": [3, None],\n",
    "              \"rfc__max_features\": randint(1, n_feats+1),\n",
    "              \"rfc__bootstrap\": [True, False],\n",
    "              \"rfc__criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfc', RandomForestClassifier(n_estimators=20))])\n",
    "\n",
    "sh = HalvingRandomSearchCV(clf, param_dist, cv=5,\n",
    "      factor=2,\n",
    "      random_state=0)\n",
    "sh.fit(X_train, y_train)\n",
    "sh.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model score: %.3f\" % sh.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dme22-EYaUUFkp-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7860b014c314f311c8b672f44810aa9dc3f93fa03e0304fc46ef46d9eb93290"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
