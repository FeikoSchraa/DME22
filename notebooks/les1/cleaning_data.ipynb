{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set some default values for our project and check the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"data/raw/\")\n",
    "outputdir = Path(\"data/processed/\")\n",
    "filename = datadir / \"les1.csv\"\n",
    "filename.resolve(), filename.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some of the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see x2 has some nans, from the count.\n",
    "Let's select all columns with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = list(df.isna().sum() > 0)\n",
    "select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now drop the nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=df.columns[select], axis=\"rows\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped 18 rows.\n",
    "Let's check the types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean out the name.\n",
    "We use a regular expression to select the first word up to the first space.\n",
    "Use https://regex101.com to create your own regular expressions.\n",
    "Or use [you.com to try with natural language](https://you.com/search?q=regular+expression+that+selects+the+first+word+up+to+a+space&fromSearchBar=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(\"^[\\w]+\")\n",
    "out = re.search(regex, \"Python Regius\")\n",
    "out.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put that into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(regex, msg):\n",
    "    out = re.search(regex, msg)\n",
    "    return out.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"name\"] = df[\"name\"].apply(lambda x: extract(regex=regex, msg=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.\n",
    "\n",
    "Now we save the file with a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "tag = datetime.now().strftime(\"%Y%m%d-%H%M\") + \".csv\"\n",
    "output = outputdir / tag\n",
    "df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of data scientists will stop here.\n",
    "\n",
    "However, while the job is done, leaving things like this is very tricky.\n",
    "Notebooks are for prototyping, not for creating a solid solution.\n",
    "\n",
    "Now, have a look at the src folder.\n",
    "Start at main.py, and also look at the other files.\n",
    "\n",
    "Now go to the terminal, cd to the `les1` directory.\n",
    "From there, you do:\n",
    "\n",
    "`poetry shell`\n",
    "\n",
    "`python src/main.py --file=les1.csv`\n",
    "\n",
    "Note how a logging.log file appears, and check that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise\n",
    "\n",
    "Inside the data/raw folder in the root directory DME22 you will find a `palmerpenguins.parq` file.\n",
    "This is a parquet file. If you always use csv, [read this](https://bawaji94.medium.com/feather-vs-parquet-vs-csv-vs-jay-55206a9a09b0) so you know why thats not a good idea.\n",
    "\n",
    "## setup\n",
    "- mkdir a new folder outside of the DME22 folder, named `cleanup`\n",
    "- initialize a new poetry environment\n",
    "- `poetry add` the libraries you need.\n",
    "- mkdir a `data/raw` folder and copy `palmerpenguins.parq`. Bonuspoints if you use the `cp` command :)  \n",
    "- mkdir a `data/processed`, `src` and `notebook` folder.\n",
    "- create a `src/main.py` file\n",
    "\n",
    "## prototype\n",
    "Make a notebook where you:\n",
    "- load the file with pandas\n",
    "- check for nans\n",
    "- figure out how you clean the out.\n",
    "- double check how many rows you throw away. Find a solution if this doesnt look good.\n",
    "- clean up the column with the names of the penguins. They are too long, so shorten them with a regex.\n",
    "- save the cleaned file with a timestamp\n",
    "\n",
    "## implement\n",
    "after you prototyped this, create a `__init__.py` file inside the `src` folder.\n",
    "Streamline the cleanup process as a command line executable process.\n",
    "Use [click](https://click.palletsprojects.com/en/8.1.x/) to create easy arguments.\n",
    "\n",
    "Try to add typehints.\n",
    "Format your code with [black](https://github.com/psf/black) by running `black src` from the command line, where src is the folder you want to format. (make sure you cd-d to the folder so that you see `src` when you ls)\n",
    "\n",
    "Add logging with loguru.\n",
    "\n",
    "Don't hardcode any settings. Use pydantic with a settings.py file.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('3.9.12': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1744316ba16fe6a768c55a6966775930ae62ed9a7643fbb4964d9580dd2f65a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
