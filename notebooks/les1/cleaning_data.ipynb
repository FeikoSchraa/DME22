{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set some default values for our project and check the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"data/raw/\")\n",
    "outputdir = Path(\"data/processed/\")\n",
    "filename = datadir / \"les1.csv\"\n",
    "filename.resolve(), filename.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some of the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see x2 has some nans, from the count.\n",
    "Let's select all columns with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = list(df.isna().sum() > 0)\n",
    "select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now drop the nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=df.columns[select], axis=\"rows\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped 18 rows.\n",
    "Let's check the types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean out the name.\n",
    "We use a regular expression to select the first word up to the first space.\n",
    "Use https://regex101.com to create your own regular expressions.\n",
    "Or use [you.com to try with natural language](https://you.com/search?q=regular+expression+that+selects+the+first+word+up+to+a+space&fromSearchBar=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(\"^[\\w]+\")\n",
    "out = re.search(regex, \"Python Regius\")\n",
    "out.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put that into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(regex, msg):\n",
    "    out = re.search(regex, msg)\n",
    "    return out.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"name\"] = df[\"name\"].apply(lambda x: extract(regex=regex, msg=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.\n",
    "\n",
    "Now we save the file with a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "tag = datetime.now().strftime(\"%Y%m%d-%H%M\") + \".csv\"\n",
    "output = outputdir / tag\n",
    "df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of data scientists will stop here.\n",
    "\n",
    "However, while the job is done, leaving things like this is very tricky.\n",
    "Notebooks are for prototyping, not for creating a solid solution.\n",
    "\n",
    "Now, have a look at the src folder.\n",
    "Start at main.py, and also look at the other files.\n",
    "\n",
    "Now go to the terminal, cd to the `les1` directory.\n",
    "From there, you do:\n",
    "\n",
    "`python src/main.py --file=les1.csv`\n",
    "\n",
    "Note how a logging.log file appears, and check that.\n",
    "\n",
    "If your terminal is complaining it cant find dependencies (eg click), this means your terminal does not know how to locate them.\n",
    "Depending on your setup, you can fix this by doing:\n",
    "`pdm run python src/main.py --file=les1.csv`.\n",
    "This tells your terminal: find the current virtual environment and use that to run the python command.\n",
    "\n",
    "Other options are to manually activate the virtual environment with `eval $(pdm venv activate)`, but this might not \n",
    "work as expected in some setups (eg the docker devcontainer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise\n",
    "\n",
    "Inside the data/raw folder in the root directory DME22 you will find a `palmerpenguins.parq` file.\n",
    "This is a parquet file. If you always use csv, [read this](https://bawaji94.medium.com/feather-vs-parquet-vs-csv-vs-jay-55206a9a09b0) so you know why thats not a good idea.\n",
    "\n",
    "## setup\n",
    "- mkdir a new folder outside of the DME22 folder, named `cleanup`\n",
    "- initialize a new virtual environment (see docs/dependencies)\n",
    "- `add` or `install` the libraries you need (eg with poetry, pip or pdm)\n",
    "- mkdir a `data/raw` folder and copy `palmerpenguins.parq`. Bonuspoints if you use the `cp` command :)  \n",
    "- mkdir a `data/processed`, `src` and `notebook` folder.\n",
    "- create a `src/main.py` file\n",
    "\n",
    "## prototype\n",
    "Make a notebook where you:\n",
    "- load the file with pandas\n",
    "- check for nans\n",
    "- figure out how you clean the out.\n",
    "- double check how many rows you throw away. Find a solution if this doesnt look good.\n",
    "- clean up the column with the names of the penguins. They are too long, so shorten them with a regex.\n",
    "- save the cleaned file with a timestamp\n",
    "\n",
    "## implement\n",
    "after you prototyped this, create a `__init__.py` file inside the `src` folder.\n",
    "Streamline the cleanup process as a command line executable process.\n",
    "Use [click](https://click.palletsprojects.com/en/8.1.x/) to create easy arguments.\n",
    "\n",
    "Try to add typehints.\n",
    "Format your code with [black](https://github.com/psf/black) by running `black src` from the command line, where src is the folder you want to format. (make sure you cd-d to the folder so that you see `src` when you ls)\n",
    "\n",
    "If your terminal does not find black, it means you either need to install black (eg `pip install black` or `pdm add black`) to your venv. If you are sure you did that (eg by checking the `/.venv/lib/python3.11/site-packages/` folder for black), then you need to activate your venv; again, this could mean you either need to add `pdm run` or do `eval $(pdm venv activate)`. What is especially tricky is that vscode will sometimes try to be helpfull and it will activate a venv for you, but it activates another venv than the one you are working in. This can be very confusing. If you are not sure, check the terminal output of the command `which python`. If it does not point to the venv you are working in, you might first need to undo vscode \"helping\" you by running `deactivate` in the terminal. If this confuses you, please practice with activating and deactivating venvs until you get familiar with it.\n",
    "\n",
    "Add logging with loguru.\n",
    "\n",
    "Don't hardcode any settings. Use pydantic with a settings.py file.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('3.9.12': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1744316ba16fe6a768c55a6966775930ae62ed9a7643fbb4964d9580dd2f65a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
